{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Understanding the Dataset \n",
    "<br>\n",
    "Description: Load a dataset and understand its basic properties including data types dimensions, and first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the data types of each column\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Display the dimensions of the dataset\n",
    "print(f\"\\nDimensions of the dataset: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Checking for Missing Values\n",
    "<br>\n",
    "Description: Identify missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Introduce some missing values\n",
    "df.loc[0, 'sepal length (cm)'] = np.nan\n",
    "df.loc[10, 'sepal width (cm)'] = np.nan\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Print the count of missing values for each column\n",
    "print(\"Count of missing values for each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Print the total count of missing values\n",
    "total_missing_values = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal count of missing values: {total_missing_values}\")\n",
    "\n",
    "# Print the percentage of missing values for each column\n",
    "missing_values_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"\\nPercentage of missing values for each column:\")\n",
    "print(missing_values_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Descriptive Statistics\n",
    "<br>\n",
    "Description: Calculate descriptive statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Calculate descriptive statistics for numerical columns\n",
    "descriptive_stats = df.describe()\n",
    "\n",
    "# Print the descriptive statistics\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Handling Outliers\n",
    "<br>\n",
    "Description: Identify outliers in numerical columns using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Box plot for each numerical column\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axs[0, 0].boxplot(df['sepal length (cm)'])\n",
    "axs[0, 0].set_title('Sepal Length')\n",
    "axs[0, 1].boxplot(df['sepal width (cm)'])\n",
    "axs[0, 1].set_title('Sepal Width')\n",
    "axs[1, 0].boxplot(df['petal length (cm)'])\n",
    "axs[1, 0].set_title('Petal Length')\n",
    "axs[1, 1].boxplot(df['petal width (cm)'])\n",
    "axs[1, 1].set_title('Petal Width')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify outliers using IQR method\n",
    "Q1 = df['sepal length (cm)'].quantile(0.25)\n",
    "Q3 = df['sepal length (cm)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['sepal length (cm)'] < lower_bound) | (df['sepal length (cm)'] > upper_bound)]\n",
    "print(\"Outliers in Sepal Length:\")\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question 5: Categorical Data Analysis\n",
    "<br>\n",
    "Description: Explore the counts of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Map target values to categorical labels\n",
    "target_mapping = {0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'}\n",
    "df['target'] = df['target'].map(target_mapping)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "category_counts = df['target'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts of categorical variables:\")\n",
    "print(category_counts)\n",
    "\n",
    "# Plot a bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "category_counts.plot(kind='bar')\n",
    "plt.title('Counts of Categorical Variables')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Data Transformation\n",
    "<br>\n",
    "Description: Transform a categorical column into numerical using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "species = iris.target_names\n",
    "df['species'] = [species[i] for i in iris.target]\n",
    "\n",
    "# Apply Label Encoding\n",
    "le = LabelEncoder()\n",
    "df['species_encoded'] = le.fit_transform(df['species'])\n",
    "\n",
    "# Print the original and encoded values\n",
    "print(\"Original values:\")\n",
    "print(df['species'].unique())\n",
    "print(\"Encoded values:\")\n",
    "print(df['species_encoded'].unique())\n",
    "\n",
    "# Print the mapping between original and encoded values\n",
    "print(\"\\nMapping between original and encoded values:\")\n",
    "for i, species in enumerate(le.classes_):\n",
    "    print(f\"{species}: {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Visualizing Data Distributions\n",
    "<br>\n",
    "Description: Plot histograms for numerical columns to understand distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axs[0, 0].hist(df['sepal length (cm)'], bins=10, edgecolor='black')\n",
    "axs[0, 0].set_title('Sepal Length Distribution')\n",
    "axs[0, 1].hist(df['sepal width (cm)'], bins=10, edgecolor='black')\n",
    "axs[0, 1].set_title('Sepal Width Distribution')\n",
    "axs[1, 0].hist(df['petal length (cm)'], bins=10, edgecolor='black')\n",
    "axs[1, 0].set_title('Petal Length Distribution')\n",
    "axs[1, 1].hist(df['petal width (cm)'], bins=10, edgecolor='black')\n",
    "axs[1, 1].set_title('Petal Width Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Correlation Analysis\n",
    "<br>\n",
    "Description: Calculate and visualize the correlation matrix for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Feature Engineering\n",
    "<br>\n",
    "Description: Create a new feature by combining or transforming existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Create a new feature: sepal area\n",
    "df['sepal_area'] = df['sepal length (cm)'] * df['sepal width (cm)']\n",
    "\n",
    "# Create a new feature: petal area\n",
    "df['petal_area'] = df['petal length (cm)'] * df['petal width (cm)']\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# You can also create a new feature by applying a transformation\n",
    "# For example, let's create a new feature: log sepal length\n",
    "import numpy as np\n",
    "df['log_sepal_length'] = np.log(df['sepal length (cm)'])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10: Advanced Outlier Detection\n",
    "<br>\n",
    "Description: Use the Z-score method to identify and handle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Calculate the Z-scores for each feature\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df))\n",
    "\n",
    "# Identify outliers using a threshold of 3 standard deviations\n",
    "threshold = 3\n",
    "outliers = df[(z_scores > threshold).any(axis=1)]\n",
    "\n",
    "# Print the outliers\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n",
    "\n",
    "# Handle outliers by removing them\n",
    "df_cleaned = df[(z_scores <= threshold).all(axis=1)]\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Alternatively, you can handle outliers by replacing them with the median or mean\n",
    "df_handled = df.copy()\n",
    "for column in df.columns:\n",
    "    median = df[column].median()\n",
    "    df_handled[column] = np.where(np.abs(stats.zscore(df[column])) > threshold, median, df[column])\n",
    "\n",
    "# Print the handled DataFrame\n",
    "print(\"Handled DataFrame:\")\n",
    "print(df_handled.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
