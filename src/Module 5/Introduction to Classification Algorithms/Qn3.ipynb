{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Popular Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 1: Predict the likelihood of a student passing a test based on study hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "np.random.seed(42)\n",
    "study_hours = np.random.randint(1, 10, size=100)\n",
    "passed = np.where(study_hours > 5, 1, 0)\n",
    "\n",
    "# Reshape the data\n",
    "study_hours = study_hours.reshape(-1, 1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(study_hours, passed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the classifier\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Predict the likelihood of a student passing the test based on study hours\n",
    "study_hours_new = np.array([[6]])  # Study hours for a new student\n",
    "prediction = logreg.predict_proba(study_hours_new)\n",
    "print(\"Likelihood of passing:\", prediction[0][1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Predict customer churn based on service usage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'usage_minutes': np.random.randint(0, 1000, size=1000),\n",
    "    'data_used_gb': np.random.uniform(0, 10, size=1000),\n",
    "    'churn': np.random.choice([0, 1], size=1000, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data[['usage_minutes', 'data_used_gb']]  # Features\n",
    "y = data['churn']  # Target (0 for not churned, 1 for churned)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Predict customer churn based on service usage data\n",
    "new_customer = pd.DataFrame({'usage_minutes': [500], 'data_used_gb': [5]})\n",
    "prediction = rf.predict(new_customer)\n",
    "print(\"Customer churn prediction:\", prediction[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Classify if a review is positive or negative using NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "np.random.seed(42)\n",
    "reviews = np.array([\n",
    "    \"This product is great!\",\n",
    "    \"I don't like this product.\",\n",
    "    \"The product is amazing!\",\n",
    "    \"The product is terrible.\",\n",
    "    \"I'm neutral about this product.\",\n",
    "    \"This product is fantastic!\",\n",
    "    \"I hate this product.\",\n",
    "    \"The product is excellent!\",\n",
    "    \"The product is awful.\",\n",
    "    \"I'm not sure about this product.\"\n",
    "] * 10)\n",
    "labels = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1] * 10)  # 1 for positive, 0 for negative\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the training data and transform both the training and testing data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classify a new review\n",
    "new_review = [\"This product is amazing!\"]\n",
    "new_review_vectorized = vectorizer.transform(new_review)\n",
    "prediction = clf.predict(new_review_vectorized)\n",
    "print(\"Review classification:\", prediction[0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
