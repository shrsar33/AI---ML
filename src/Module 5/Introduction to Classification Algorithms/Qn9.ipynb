{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Classification Model Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-Title: Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Construct and interpret a confusion matrix for tumor classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample dataset (replace with your actual dataset)\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'tumor_type': np.random.choice(['Benign', 'Malignant'], size=100)\n",
    "})\n",
    "\n",
    "# Map tumor type to numerical values\n",
    "tumor_map = {'Benign': 0, 'Malignant': 1}\n",
    "data['tumor_type'] = data['tumor_type'].map(tumor_map)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['tumor_type']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Interpret the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate metrics from the confusion matrix\n",
    "TP = cm[1, 1]  # True positives\n",
    "TN = cm[0, 0]  # True negatives\n",
    "FP = cm[0, 1]  # False positives\n",
    "FN = cm[1, 0]  # False negatives\n",
    "\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "print(\"Sensitivity (Recall):\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Create a confusion matrix for fraud detection model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample dataset (replace with your actual dataset)\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'is_fraud': np.random.choice([0, 1], size=100, p=[0.9, 0.1])  # 1: Fraud, 0: Not Fraud\n",
    "})\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics from the confusion matrix\n",
    "TP = cm[1, 1]  # True positives (fraud correctly identified)\n",
    "TN = cm[0, 0]  # True negatives (non-fraud correctly identified)\n",
    "FP = cm[0, 1]  # False positives (non-fraud incorrectly identified as fraud)\n",
    "FN = cm[1, 0]  # False negatives (fraud incorrectly identified as non-fraud)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 3: Use confusion matrix to evaluate model predicting employee retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample dataset (replace with your actual dataset)\n",
    "data = pd.DataFrame({\n",
    "    'satisfaction_level': np.random.rand(100),\n",
    "    'last_evaluation': np.random.rand(100),\n",
    "    'retention': np.random.choice([0, 1], size=100, p=[0.7, 0.3])  # 1: Retained, 0: Not Retained\n",
    "})\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data[['satisfaction_level', 'last_evaluation']]\n",
    "y = data['retention']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics from the confusion matrix\n",
    "TP = cm[1, 1]  # True positives (retained employees correctly predicted)\n",
    "TN = cm[0, 0]  # True negatives (not retained employees correctly predicted)\n",
    "FP = cm[0, 1]  # False positives (not retained employees incorrectly predicted as retained)\n",
    "FN = cm[1, 0]  # False negatives (retained employees incorrectly predicted as not retained)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"F1-score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
